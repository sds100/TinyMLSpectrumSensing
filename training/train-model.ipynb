{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T17:18:01.776609Z",
     "start_time": "2024-05-22T17:18:01.773445Z"
    }
   },
   "source": [
    "from importlib import reload\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import scipy.io as sio\n",
    "import seaborn\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, losses\n",
    "\n",
    "import spectrum_painting as sp\n",
    "import spectrum_painting_model as sp_model\n",
    "from spectrogram import Spectrogram, split_spectrogram\n",
    "from spectrogram import create_spectrogram"
   ],
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T17:18:01.820808Z",
     "start_time": "2024-05-22T17:18:01.818602Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))",
   "id": "ddb82b69f8e88134",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "id": "dfc8ac0d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-22T17:18:01.827172Z"
    }
   },
   "source": [
    "def load_data_from_matlab(file: str) -> npt.NDArray[np.complex128]:\n",
    "    \"\"\"\n",
    "    Load the list of complex numbers from Matlab files.\n",
    "    \"\"\"\n",
    "    # each complex number is in its own row and so is put in\n",
    "    # its own array. 'squeeze' flattens the array.\n",
    "    return sio.loadmat(file)[\"WaveformOut\"].squeeze()\n",
    "\n",
    "\n",
    "data: Dict[str, npt.NDArray[np.complex128]] = {\n",
    "    \"z\": load_data_from_matlab(\"data/matlab/SNR30_Z.mat\"),\n",
    "    \"b\": load_data_from_matlab(\"data/matlab/SNR30_B.mat\"),\n",
    "    \"w\": load_data_from_matlab(\"data/matlab/SNR30_W.mat\"),\n",
    "    \"bw\": load_data_from_matlab(\"data/matlab/SNR30_BW.mat\"),\n",
    "    \"zb\": load_data_from_matlab(\"data/matlab/SNR30_ZB.mat\"),\n",
    "    \"zw\": load_data_from_matlab(\"data/matlab/SNR30_ZW.mat\"),\n",
    "    \"zbw\": load_data_from_matlab(\"data/matlab/SNR30_ZBW.mat\"),\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85bb35ba857cae96",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def plot_spectrogram(spectrogram: Spectrogram):\n",
    "    plt.pcolormesh(spectrogram.f, spectrogram.t, spectrogram.values.T, shading=\"nearest\", cmap=\"viridis\")\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    plt.title(\"Spectrogram\")\n",
    "    plt.colorbar(label=\"Magnitude (dB)\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0056fdbb",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Sampling frequency\n",
    "fs = 20000000  # 20MHz\n",
    "\n",
    "spectrograms: Dict[str, Spectrogram] = {key: create_spectrogram(frame, fs) for key, frame in data.items()}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee38cb7c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "reload(sp)\n",
    "# middle: int = len(spectrograms[\"zbw\"].values) // 2\n",
    "# start_freq: int = middle - 40\n",
    "# end_freq: int = middle + 40\n",
    "# \n",
    "# demo_spectrogram = sp.take_frequencies(spectrograms[\"zbw\"], start_freq, end_freq)\n",
    "# demo_spectrogram = split_spectrogram(demo_spectrogram, 1000)[0]\n",
    "# demo_spectrogram.values = demo_spectrogram.values.clip(0, 0.0000001)\n",
    "# \n",
    "# plt.pcolormesh(demo_spectrogram.f, demo_spectrogram.t, demo_spectrogram.values.T, shading=\"nearest\")\n",
    "# plt.show()\n",
    "# \n",
    "# demo_spectrogram = sp.downsample_spectrogram(demo_spectrogram.values, 16)\n",
    "# plt.imshow(demo_spectrogram.T)\n",
    "# plt.show()\n",
    "# \n",
    "# augmented_demo_spectrogram = sp.augment_spectrogram(spectrogram=demo_spectrogram, k=4, l=3, d=1)\n",
    "# plt.imshow(augmented_demo_spectrogram)\n",
    "# plt.show()\n",
    "# \n",
    "# demo_spectrogram = sp.paint_spectrogram(demo_spectrogram, augmented_demo_spectrogram)\n",
    "# demo_spectrogram = sp.digitize_spectrogram(demo_spectrogram, 256)\n",
    "# plt.imshow(demo_spectrogram)\n",
    "# plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1965bdfb6000df17",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Reload spectrum painting module in case the code changed\n",
    "# and you want what is executed to be what you told the computer\n",
    "# to do.\n",
    "reload(sp)\n",
    "\n",
    "downsample_resolution = 32\n",
    "\n",
    "K = 3\n",
    "L = 1\n",
    "D = 1\n",
    "\n",
    "color_depth = 256\n",
    "\n",
    "x_train_augmented: List[npt.NDArray[np.float32]] = []\n",
    "x_train_painted: List[npt.NDArray[np.float32]] = []\n",
    "labels: List[np.uint8] = []\n",
    "label_names: List[str] = []\n",
    "\n",
    "for (class_index, (label, spec)) in enumerate(spectrograms.items()):\n",
    "    middle: int = len(spec.values) // 2\n",
    "    start_freq: int = middle - 32\n",
    "    end_freq: int = middle + 32\n",
    "\n",
    "    spec = sp.take_frequencies(spec, start_freq, end_freq)\n",
    "\n",
    "    slices = split_spectrogram(spec, duration=4000)\n",
    "\n",
    "    downsampled_slices = [sp.downsample_spectrogram(s.values, downsample_resolution) for s in slices]\n",
    "    augmented_slices = [sp.augment_spectrogram(s, K, L, D) for s in downsampled_slices]\n",
    "\n",
    "    for s in augmented_slices:\n",
    "        x_train_augmented.append(sp.digitize_spectrogram(s, color_depth))\n",
    "\n",
    "    painted_slices = [sp.paint_spectrogram(original, augmented) for (original, augmented) in\n",
    "                      list(zip(downsampled_slices, augmented_slices))]\n",
    "\n",
    "    for s in painted_slices:\n",
    "        x_train_painted.append(sp.digitize_spectrogram(s, color_depth))\n",
    "\n",
    "    for i in range(len(slices)):\n",
    "        labels.append(class_index)\n",
    "\n",
    "    label_names.append(label)\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for i in range(len(x_train_painted)):\n",
    "    image = x_train_augmented[i]\n",
    "    plt.subplot(20, 20, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image, cmap=\"viridis\")\n",
    "    plt.xlabel(label_names[labels[i]])\n",
    "plt.show()\n",
    "\n",
    "x_train_combined = np.stack((x_train_augmented, x_train_painted), axis=3)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_combined, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# for tensorflow it must be uint8 and not a Python int.\n",
    "y_train = np.array(y_train, dtype=np.uint8)\n",
    "y_test = np.array(y_test, dtype=np.uint8)\n",
    "\n",
    "x_train_augmented = x_train[:, :, :, 0]\n",
    "x_test_augmented = x_test[:, :, :, 0]\n",
    "\n",
    "x_train_painted = x_train[:, :, :, 1]\n",
    "x_test_painted = x_test[:, :, :, 1]\n",
    "\n",
    "print(f\"Number of training images: {len(x_train)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "115aed9b631fed91",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "image_shape = x_train_augmented[0].shape\n",
    "# The input shape to the CNN is the height, width and number of color channels. The spectrograms\n",
    "# only have one color channel.\n",
    "input_shape = (image_shape[0], image_shape[1], 1)\n",
    "print(input_shape)\n",
    "\n",
    "augmented_input = layers.Input(shape=input_shape)\n",
    "augmented_model = layers.Conv2D(filters=64, kernel_size=(7, 7), activation='relu')(augmented_input)\n",
    "augmented_model = layers.BatchNormalization()(augmented_model)\n",
    "augmented_model = layers.MaxPooling2D((2, 2))(augmented_model)\n",
    "\n",
    "augmented_model = layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu')(augmented_model)\n",
    "augmented_model = layers.BatchNormalization()(augmented_model)\n",
    "augmented_model = layers.MaxPooling2D((2, 2))(augmented_model)\n",
    "\n",
    "augmented_model = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(augmented_model)\n",
    "augmented_model = layers.BatchNormalization()(augmented_model)\n",
    "augmented_model = layers.MaxPooling2D((2, 2))(augmented_model)\n",
    "\n",
    "# Flatten the 3D image output to 1 dimension\n",
    "augmented_model = layers.Flatten()(augmented_model)\n",
    "painted_input = layers.Input(shape=input_shape)\n",
    "painted_model = layers.Conv2D(filters=64, kernel_size=(7, 7), activation='relu', input_shape=input_shape)(painted_input)\n",
    "painted_model = layers.BatchNormalization()(painted_model)\n",
    "painted_model = layers.MaxPooling2D((2, 2))(painted_model)\n",
    "\n",
    "painted_model = layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu')(painted_model)\n",
    "painted_model = layers.BatchNormalization()(painted_model)\n",
    "painted_model = layers.MaxPooling2D((2, 2))(painted_model)\n",
    "\n",
    "painted_model = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(painted_model)\n",
    "painted_model = layers.BatchNormalization()(painted_model)\n",
    "painted_model = layers.MaxPooling2D((2, 2))(painted_model)\n",
    "\n",
    "# Flatten the 3D image output to 1 dimension\n",
    "painted_model = layers.Flatten()(painted_model)\n",
    "\n",
    "output = layers.Concatenate()([augmented_model, painted_model])\n",
    "output = layers.Dense(64, activation='relu')(output)\n",
    "\n",
    "label_count = len(spectrograms)\n",
    "output = layers.Dense(label_count)(output)\n",
    "\n",
    "tf_model = models.Model(inputs=[augmented_input, painted_input], outputs=[output])\n",
    "\n",
    "tf_model.summary()\n",
    "tf.keras.utils.plot_model(tf_model, to_file=\"output/model.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "55929ef6ba001366",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "tf_model.compile(optimizer='adam',\n",
    "                 loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# convert ints to the type of int that can be used in a Tensor\n",
    "history = tf_model.fit(x=[x_train_augmented, x_train_painted],\n",
    "                       y=y_train,\n",
    "                       epochs=300,\n",
    "                       validation_data=([x_test_augmented, x_test_painted], y_test))\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 2])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d0c33e2222aa6e88"
  },
  {
   "cell_type": "code",
   "id": "a80693627da5a6e1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "final_loss, final_acc = tf_model.evaluate([x_test_augmented, x_test_painted], y_test, verbose=1)\n",
    "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8e38174f677ca0d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "output_file = \"output/spectrum-painting-model.keras\"\n",
    "\n",
    "tf.saved_model.save(tf_model, \"output/\")\n",
    "tf_model.save(output_file)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f518967be0c8682b"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict with full Tensorflow\n",
    "test_img_augmented = x_test_augmented[17]\n",
    "test_img_painted = x_test_painted[17]\n",
    "\n",
    "plt.imshow(test_img_augmented, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "prediction = sp_model.predict_full_model(tf_model, test_img_augmented, test_img_painted)\n",
    "\n",
    "print(label_names[prediction])"
   ],
   "id": "521026c640e5598b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(y_predictions: npt.NDArray[np.uint8],\n",
    "                          y_test: npt.NDArray[np.uint8]):\n",
    "    cm = confusion_matrix(y_test, y_predictions)\n",
    "    cm = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])\n",
    "\n",
    "    plt.figure()\n",
    "    plot = seaborn.heatmap(cm, xticklabels=label_names, yticklabels=label_names, annot=True, cmap='Blues')\n",
    "    plot.get_figure()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicated Label')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "tf_model_y_predictions = [sp_model.predict_full_model(tf_model, x_a, x_p) for (x_a, x_p) in\n",
    "                          zip(x_test_augmented, x_test_painted)]\n",
    "plot_confusion_matrix(tf_model_y_predictions, y_test)"
   ],
   "id": "f10f0a0dfde59a08",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b80cf94dd7d2bbf",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def representative_data_gen():\n",
    "    # Convert test images to float32 and the correct dimensions\n",
    "    # for TensorFlow to do full-integer quantization.\n",
    "    repr_augmented_images = np.copy(x_test_augmented)\n",
    "    repr_augmented_images = [img.astype(np.float32) for img in repr_augmented_images]\n",
    "\n",
    "    for img in repr_augmented_images:\n",
    "        img.shape += (1,)\n",
    "\n",
    "    repr_painted_images = np.copy(x_test_painted)\n",
    "    repr_painted_images = [img.astype(np.float32) for img in repr_painted_images]\n",
    "\n",
    "    for img in repr_painted_images:\n",
    "        img.shape += (1,)\n",
    "\n",
    "    augmented_images = tf.data.Dataset.from_tensor_slices(repr_augmented_images).batch(1).take(100)\n",
    "    painted_images = tf.data.Dataset.from_tensor_slices(repr_painted_images).batch(1).take(100)\n",
    "    for aug_value, painted_value in list(zip(augmented_images, painted_images)):\n",
    "        # Model has only one input so each data point has one element.\n",
    "\n",
    "        yield [aug_value, painted_value]\n",
    "\n",
    "\n",
    "# This requires TensorFlow <= 2.15.0 for it to work. See https://github.com/tensorflow/tensorflow/issues/63987\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tf_model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "print(\"Converting...\")\n",
    "tflite_model = converter.convert()\n",
    "print(f\"Done. Model size = {len(tflite_model) // 1000} KB\")\n",
    "\n",
    "# Save the model.\n",
    "with open('output/spectrum-painting-model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "774ddb2d633e0ec8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "de9fda3702bd1dab",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "reload(sp_model)\n",
    "\n",
    "# Test with Tensorflow Lite\n",
    "test_img_augmented = x_test_augmented[1]\n",
    "test_img_painted = x_test_painted[1]\n",
    "\n",
    "plt.imshow(test_img_augmented, cmap=\"viridis\")\n",
    "plt.show()\n",
    "\n",
    "prediction = sp_model.predict_lite_model(tflite_model, test_img_augmented, test_img_painted)\n",
    "print(f\"Prediction: {label_names[prediction]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "tflite_model_y_predictions: List[int] = []\n",
    "\n",
    "for x_aug, x_painted in list(zip(x_test_augmented, x_test_painted)):\n",
    "    tflite_model_y_predictions.append(sp_model.predict_lite_model(tflite_model, x_aug, x_painted))\n",
    "\n",
    "accuracy = np.sum(y_test == tflite_model_y_predictions) / len(x_test_augmented)\n",
    "\n",
    "print(f\"Lite model accuracy = {accuracy}\")\n",
    "plot_confusion_matrix(np.asarray(tflite_model_y_predictions), y_test)"
   ],
   "id": "6fb84ddb5dd0d5ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da54d63f54bee024",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "test_img_augmented = x_test_augmented[9]\n",
    "test_img_painted = x_test_painted[9]\n",
    "\n",
    "print(test_img_augmented.shape)\n",
    "\n",
    "plt.imshow(test_img_augmented, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(test_img_painted, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "test_img_augmented.shape += (1,)\n",
    "test_img_augmented = (np.expand_dims(test_img_augmented, 0))\n",
    "test_img_augmented = test_img_augmented.astype(np.uint8)\n",
    "\n",
    "test_img_painted.shape += (1,)\n",
    "test_img_painted = (np.expand_dims(test_img_painted, 0))\n",
    "test_img_painted = test_img_painted.astype(np.uint8)\n",
    "\n",
    "with open('output/augmented_image.bytes', 'wb') as f:\n",
    "    f.write(test_img_augmented.flatten())\n",
    "\n",
    "with open('output/painted_image.bytes', 'wb') as f:\n",
    "    f.write(test_img_painted.flatten())\n",
    "\n",
    "# with serial.Serial(\"/dev/cu.usbmodem2101\", timeout=5) as ser:\n",
    "#     ser.write(augmented_bytes)\n",
    "#     ser.write(painted_bytes)\n",
    "#     print(ser.readline())\n",
    "#     print(ser.readline())\n",
    "#     print(ser.readline())\n",
    "#     print(ser.readline())\n",
    "#     print(ser.readline())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d338edf3099d012",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Verify what was wrote is the same\n",
    "# test_img_read_aug: bytearray\n",
    "# test_img_read_painted: bytearray\n",
    "# \n",
    "# with open('output/augmented_image.bytes', 'rb') as f:\n",
    "#     test_img_read_aug = bytearray(f.read())\n",
    "# \n",
    "# with open('output/painted_image.bytes', 'rb') as f:\n",
    "#     test_img_read_painted = bytearray(f.read())\n",
    "# \n",
    "# prediction = sp_model.predict_lite_model(tflite_model, np.asarray(test_img_read_aug).reshape(32, 32),\n",
    "#                                          np.asarray(test_img_read_painted).reshape(32, 32))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
